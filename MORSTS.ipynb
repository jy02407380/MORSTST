{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a block generator to obtain different initial data sets\n",
    "\n",
    "#  n is the number of parts into which it is divided, i is the serial number of the block/batch\n",
    "def getChunks(data,n,i):\n",
    "    return data[ int(len(data)*(i)/n)+1 : (int(len(data)*(i+1)/n)-1)]\n",
    "def getPourCentage(data,beginCentage,endCentage):\n",
    "    return data[ (int(len(data)*beginCentage)): (int(len(data)*endCentage))]\n",
    "\n",
    "#Function description: return initial data, return all training data, determine if a next batch exists, return current batch.\n",
    "class feeder_Ini_Train_Batch():\n",
    "    def __init__(self,X,Y,beginCentage,endCentage,batch_size):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        #elf.X_train = getPourCentage(X,0,iniCentage)\n",
    "        #elf.Y_train = getPourCentage(Y,0,iniCentage)\n",
    "        self.X_test = getPourCentage(X,beginCentage,endCentage)\n",
    "        self.Y_test = getPourCentage(Y,beginCentage,endCentage)\n",
    "        self.batch_size = batch_size\n",
    "        self.t = 1 # ‘t’ is indexing and time. \n",
    "    def getIni_X_Y(self,iniCentage):\n",
    "        return getPourCentage(self.X,0,iniCentage),getPourCentage(self.Y,0,iniCentage)\n",
    "    def getTrain_X_Y(self):\n",
    "        return self.X_test,self.Y_test\n",
    "    def hasThisBatch(self):\n",
    "        if (self.t)*self.batch_size < len (self.X_test):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def hasThisBatch_and_nextBath(self):\n",
    "        if (self.t+1)*(self.batch_size) < len (self.X_test):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def getThisBatch(self):\n",
    "        if self.hasThisBatch() == True:\n",
    "            actul_Batch_X = self.X_test[(self.t-1)*self.batch_size:(self.t)*self.batch_size]\n",
    "            actul_Batch_Y = self.Y_test[(self.t-1)*self.batch_size:(self.t)*self.batch_size]\n",
    "            return actul_Batch_X,actul_Batch_Y\n",
    "        else:\n",
    "            print('err index out')\n",
    "    def getNextBatch_getThisBatch(self):\n",
    "        if self.hasThisBatch() == True:\n",
    "            next_Batch_X = self.X_test[(self.t)*self.batch_size:(self.t+1)*self.batch_size]\n",
    "            next_Batch_Y = self.Y_test[(self.t)*self.batch_size:(self.t+1)*self.batch_size]\n",
    "            return next_Batch_X,next_Batch_Y\n",
    "        else:\n",
    "            print('err index out')\n",
    "    def goNext(self):\n",
    "        self.t +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanSuperPourCentage(data,PourCentage): # Calculate the average value of （the top percentage of） the data. \n",
    "#     print(np.percentile(data, (PourCentage)))\n",
    "    return np.mean([x for x in data if x >= np.percentile(data, (PourCentage))])\n",
    "def getMeanSuperPourCentage_Martix_ParLine(data,PourCentage):\n",
    "    return np.array([getMeanSuperPourCentage(x,PourCentage) for x in data ])\n",
    "\n",
    "# 0 submodel 1 numbering time 2 weights 3 class name 4 common name 5 varepsilon weighting error 6 Omega time weighting 7 err common RMSE error 8 model address\n",
    "\n",
    "def RandonSelectionModle(index,x,y , optitionInnErrOrCroissErr,numFlod = 3, indique_sousModle = 'Random_LS_LI_R_T'):  \n",
    "\n",
    "    if indique_sousModle == 'Random_LI_R_T_KNN':\n",
    "        indique_sousModle = choice(['Lasso','R_Forest','Tree','KNN'])\n",
    "#     elif indique_sousModle == 'Random_LS_LI_R_T_KNN':\n",
    "#         indique_sousModle = choice(['LSTM','Lasso','R_Forest','Tree','KNN'])\n",
    "#     elif indique_sousModle == 'Random_LS_LI_R_T_SVR':\n",
    "#         indique_sousModle = choice(['LSTM','Lasso','R_Forest','Tree','SVR'])\n",
    "#     elif indique_sousModle == 'Random_LS_LI_R_T':\n",
    "#         indique_sousModle = choice(['LSTM','Lasso','R_Forest','Tree'])\n",
    "#     elif indique_sousModle == 'Random_LS_LI_R_KNN':\n",
    "#         indique_sousModle = choice(['LSTM','Lasso','R_Forest','KNN'])\n",
    "#     elif indique_sousModle == 'Random_LS_LI_T_KNN':\n",
    "#         indique_sousModle = choice(['LSTM','Lasso','Tree','KNN'])\n",
    "#     elif indique_sousModle == 'Random_LS_R_T_KNN':\n",
    "#         indique_sousModle = choice(['LSTM','R_Forest','Tree','KNN'])\n",
    "#     elif indique_sousModle == 'Random_LS_R_T':\n",
    "#         indique_sousModle = choice(['LSTM','R_Forest','Tree'])\n",
    "#     elif indique_sousModle == 'Random_LS_LI_T':\n",
    "#         indique_sousModle = choice(['LSTM','Lasso','Tree'])\n",
    "        \n",
    "        print('Randomly selected indique_sousModle ',indique_sousModle)\n",
    "    weight = 1 # weight of  this base model \n",
    "    varepsilon = 1 # Results of the loss functions\n",
    "    omega = 1 #  Weight of time\n",
    "    RMSE = 1 # Common RMSE error\n",
    "    x_rnn = np.reshape(x, (x.shape[0], 1,x.shape[1]))\n",
    "    kf = KFold(n_splits=numFlod)\n",
    "    yhat_all_flod = []\n",
    "    \n",
    "\n",
    "    \n",
    "#     elif indique_sousModle == 'LSTM' :\n",
    "#         modele = Sequential()\n",
    "#         modele.add(LSTM(500, input_shape =(1, x_rnn.shape[2]) , activation='relu'))\n",
    "#         modele.add(Dense(500, activation='relu'))\n",
    "#         modele.add(Dense(y.shape[1] , activation='sigmoid'))\n",
    "#         # Compile model\n",
    "#         modele.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#         modele.fit(x_rnn, y, epochs=6, batch_size=2000,  verbose=2)\n",
    "#         if optitionInnErrOrCroissErr == 'CroissErr':\n",
    "#             for train, test in kf.split(x_rnn):\n",
    "#                 X_train_numFlod = np.array( [x_rnn[i] for i in train])\n",
    "#                 Y_train_numFlod = np.array([y[i] for i in train])\n",
    "#                 X_test_numFlod = np.array([x_rnn[i] for i in test])\n",
    "#                 Y_test_numFlod = np.array([y[i] for i in test])\n",
    "#                 modele_numFlod = Sequential()\n",
    "#                 modele_numFlod.add(LSTM(500, input_shape =(1, x_rnn.shape[2]) , activation='relu'))\n",
    "#                 modele_numFlod.add(Dense(500, activation='relu'))\n",
    "#                 modele_numFlod.add(Dense(y.shape[1] , activation='sigmoid'))\n",
    "#                 modele_numFlod.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#                 modele_numFlod.fit(X_train_numFlod, Y_train_numFlod, epochs=4, batch_size=1000,  verbose=2)\n",
    "#                 yhat__numFlod = modele_numFlod.predict(X_test_numFlod)\n",
    "#                 yhat_all_flod += yhat__numFlod.tolist()\n",
    "#         return [modele,index,weight,modele.__class__,'LSTM',varepsilon,omega,RMSE,id(modele)] , yhat_all_flod\n",
    "    \n",
    "    \n",
    "    \n",
    "#     elif indique_sousModle == 'SVR' :\n",
    "#         modele = MSVR_F()\n",
    "#         modele.fit(x,y)\n",
    "#         if optitionInnErrOrCroissErr == 'CroissErr':\n",
    "#             for train, test in kf.split(x):\n",
    "#                 X_train_numFlod = np.array( [x[i] for i in train])\n",
    "#                 Y_train_numFlod = np.array([y[i] for i in train])\n",
    "#                 X_test_numFlod = np.array([x[i] for i in test])\n",
    "#                 Y_test_numFlod = np.array([y[i] for i in test])\n",
    "#                 modele_numFlod = MSVR_F()\n",
    "#                 modele_numFlod.fit(X_train_numFlod,Y_train_numFlod)\n",
    "#                 yhat__numFlod = modele_numFlod.predict(X_test_numFlod)\n",
    "#                 yhat_all_flod += yhat__numFlod.tolist()        \n",
    "#         return [modele,index,weight,modele.__class__,'SVR',varepsilon,omega,RMSE,id(modele)],yhat_all_flod\n",
    "    \n",
    "\n",
    "    if indique_sousModle == 'KNN':\n",
    "        modele = KNeighborsRegressor(n_neighbors=15)\n",
    "        modele.fit(x,y)\n",
    "        if optitionInnErrOrCroissErr == 'CroissErr':\n",
    "            for train, test in kf.split(x):\n",
    "                X_train_numFlod = np.array( [x[i] for i in train])\n",
    "                Y_train_numFlod = np.array([y[i] for i in train])\n",
    "                X_test_numFlod = np.array([x[i] for i in test])\n",
    "                Y_test_numFlod = np.array([y[i] for i in test])\n",
    "                modele_numFlod = KNeighborsRegressor(n_neighbors=15)\n",
    "                modele_numFlod.fit(X_train_numFlod,Y_train_numFlod)\n",
    "                yhat__numFlod = modele_numFlod.predict(X_test_numFlod)\n",
    "                yhat_all_flod += yhat__numFlod.tolist()        \n",
    "        return [modele,index,weight,modele.__class__,'KNeighborsRegressor',varepsilon,omega,RMSE,id(modele)],yhat_all_flod\n",
    "    \n",
    "    elif indique_sousModle == 'R_Forest':\n",
    "        modele = RandomForestRegressor(n_estimators=10, )\n",
    "        modele.fit(x,y)\n",
    "        if optitionInnErrOrCroissErr == 'CroissErr':\n",
    "            for train, test in kf.split(x):\n",
    "                X_train_numFlod = np.array( [x[i] for i in train])\n",
    "                Y_train_numFlod = np.array([y[i] for i in train])\n",
    "                X_test_numFlod = np.array([x[i] for i in test])\n",
    "                Y_test_numFlod = np.array([y[i] for i in test])\n",
    "                modele_numFlod = RandomForestRegressor(n_estimators=10,)\n",
    "                modele_numFlod.fit(X_train_numFlod,Y_train_numFlod)\n",
    "                yhat__numFlod = modele_numFlod.predict(X_test_numFlod)\n",
    "                yhat_all_flod += yhat__numFlod.tolist()\n",
    "        return [modele,index,weight,modele.__class__,'RandomForestRegressor',varepsilon,omega,RMSE,id(modele)],yhat_all_flod\n",
    "            \n",
    "    elif indique_sousModle == 'Lasso':\n",
    "        modele = Lasso(alpha=0.1)\n",
    "        modele.fit(x,y)\n",
    "        if optitionInnErrOrCroissErr == 'CroissErr':\n",
    "            for train, test in kf.split(x):\n",
    "                X_train_numFlod = np.array( [x[i] for i in train])\n",
    "                Y_train_numFlod = np.array([y[i] for i in train])\n",
    "                X_test_numFlod = np.array([x[i] for i in test])\n",
    "                Y_test_numFlod = np.array([y[i] for i in test])\n",
    "                modele_numFlod = Lasso(alpha=0.1)\n",
    "                modele_numFlod.fit(X_train_numFlod,Y_train_numFlod)\n",
    "                yhat__numFlod = modele_numFlod.predict(X_test_numFlod)\n",
    "                yhat_all_flod += yhat__numFlod.tolist()        \n",
    "        return [modele,index,weight,modele.__class__,'LassoRegression',varepsilon,omega,RMSE,id(modele)],yhat_all_flod\n",
    "        \n",
    "    elif indique_sousModle == 'Tree':\n",
    "        modele = DecisionTreeRegressor()\n",
    "        modele.fit(x,y)\n",
    "        if optitionInnErrOrCroissErr == 'CroissErr':\n",
    "            for train, test in kf.split(x):\n",
    "                X_train_numFlod = np.array( [x[i] for i in train])\n",
    "                Y_train_numFlod = np.array([y[i] for i in train])\n",
    "                X_test_numFlod = np.array([x[i] for i in test])\n",
    "                Y_test_numFlod = np.array([y[i] for i in test])\n",
    "                modele_numFlod = DecisionTreeRegressor()\n",
    "                modele_numFlod.fit(X_train_numFlod,Y_train_numFlod)\n",
    "                yhat__numFlod = modele_numFlod.predict(X_test_numFlod)\n",
    "                yhat_all_flod += yhat__numFlod.tolist()        \n",
    "        return [modele,index,weight,modele.__class__,'DecisionTreeRegressor',varepsilon,omega,RMSE,id(modele)],yhat_all_flod\n",
    "        \n",
    "def makePredictionModele(modele,x):\n",
    "    if type(modele) in [type(RandomForestRegressor()), \n",
    "                          type(KNeighborsRegressor()),\n",
    "                          type(Lasso()),\n",
    "                          type(DecisionTreeRegressor())] :\n",
    "\n",
    "        return  modele.predict(x)\n",
    "    else:\n",
    "        print('Error reported, not in the list')\n",
    "\n",
    "def beta_fonction(k,t,a,b):  \n",
    "    return 1/(1+ math.exp(-a*(t-k-b))) \n",
    "\n",
    "def vote_mean(dic_expert, actul_Batch_X, actul_Batch_Y, afficher_detail = False):\n",
    "    H_res = np.array( [[0.0]* len(actul_Batch_Y[0])] *len(actul_Batch_Y))\n",
    "    print(H_res)\n",
    "    sumWeigt = 0\n",
    "    \n",
    "    list_RMSE_SousModele = []\n",
    "\n",
    "    for key,value in dic_expert.items():\n",
    "        yhat_sousM = makePredictionModele(value[0],actul_Batch_X)\n",
    "        \n",
    "        if np.array(yhat_sousM).ndim == 1:\n",
    "            print('type([[z] for z in yhat_sousM])  ',type([[z] for z in yhat_sousM]))\n",
    "            yhat_sousModel = np.array([[z] for z in yhat_sousM])\n",
    "        else:\n",
    "            yhat_sousModel = yhat_sousM\n",
    "            print(type(yhat_sousModel))\n",
    "        print('Output of each sub-model',yhat_sousModel)\n",
    "        H_res =H_res + yhat_sousModel*value[2]\n",
    "        sumWeigt += value[2] #  2 2 represents the vote weights of the sub model \n",
    "        list_RMSE_SousModele.append(aRMSE( actul_Batch_Y ,yhat_sousModel))\n",
    "    yhat_H = np.array(H_res)/sumWeigt # Obtaining the predicted results \n",
    "    \n",
    "#     print('Output after the end of voting', yhat_H)\n",
    "#     print('Original value of Y', actul_Batch_Y)\n",
    "    if afficher_detail == True:\n",
    "        print( 'list_RMSE_SousModele ', list_RMSE_SousModele, 'mean of list_RMSE_SousModele', np.mean(list_RMSE_SousModele) )\n",
    "        print(' RMSE resultat vote', aRMSE( actul_Batch_Y ,yhat_H))\n",
    "    return yhat_H\n",
    "\n",
    "\n",
    "def vote_OnlyMaxERRWeight(dic_expert, actul_Batch_X, actul_Batch_Y):\n",
    "    the_key = 0\n",
    "    maxWeight = 0\n",
    "    for key,value in dic_expert.items():\n",
    "        if dic_expert[key][5] > maxWeight:\n",
    "            maxWeight = dic_expert[key][5]\n",
    "            the_key = key\n",
    "    yhat_H = makePredictionModele(dic_expert[the_key][0],actul_Batch_X)\n",
    "    err_H =  aRMSE(actul_Batch_Y,yhat_H)# err as RMSE \n",
    "    print('Sub-model selected to vote, no. ', the_key, ' with its RMSE', err_H)\n",
    "    return yhat_H\n",
    "\n",
    "def vote_OnlyMaxESpWeight(dic_expert, actul_Batch_X, actul_Batch_Y):\n",
    "    the_key = 0\n",
    "    maxWeight = 0\n",
    "    for key,value in dic_expert.items():\n",
    "        if dic_expert[key][2] > maxWeight:\n",
    "            maxWeight = dic_expert[key][2]\n",
    "            the_key = key\n",
    "    yhat_H = makePredictionModele(dic_expert[the_key][0],actul_Batch_X)\n",
    "    err_H =  aRMSE(actul_Batch_Y,yhat_H)# err as RMSE \n",
    "    print('Sub-model selected to vote, no. ', the_key, ' with its RMSE', err_H)\n",
    "    return yhat_H\n",
    "\n",
    "def updatingALLSousModele(dic_expert, x, y):\n",
    "    print (' Update sub-model program start' )\n",
    "    x_rnn = np.reshape(x, (x.shape[0], 1,x.shape[1]))\n",
    "    for key,value in dic_expert.items():\n",
    "        if type(value[0]) in [type(Sequential())]:\n",
    "            value[0].fit(x_rnn, actul_Batch_Y)\n",
    "\n",
    "            \n",
    "def get_filename(path,filetype):  # Enter the path, file type e.g. '.csv'\n",
    "    name = []\n",
    "    for root,dirs,files in os.walk(path):\n",
    "        for i in files:\n",
    "            if os.path.splitext(i)[1]==filetype:\n",
    "                name.append(i)    \n",
    "    return name\n",
    "\n",
    "def aRMSE(y_true,y_pred):\n",
    "    return np.mean(mean_squared_error(y_true, y_pred, squared=False, multioutput='raw_values'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected indique_sousModle  R_Forest\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00826631 0.01272912 ... 0.01726049 0.         0.        ]\n",
      " [0.         0.00705987 0.01283096 ... 0.01694378 0.         0.        ]\n",
      " [0.         0.00174263 0.01639511 ... 0.01797308 0.         0.        ]\n",
      " ...\n",
      " [0.46385984 0.36179625 0.31670061 ... 0.02889945 0.11295861 0.44907162]\n",
      " [0.45765915 0.35924933 0.31863544 ... 0.02842439 0.11223568 0.45225464]\n",
      " [0.41753807 0.37645219 0.3395112  ... 0.03230404 0.11852521 0.47639257]]\n",
      "list_RMSE_SousModele  [0.0978164999965197] mean of list_RMSE_SousModele 0.0978164999965197\n",
      " RMSE resultat vote 0.0978164999965197\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  KNN\n",
      "key  0  value[6]  0.5474158342212556\n",
      "key  1  value[6]  1.0\n",
      "key  0 value[2]  0.11331814696222602\n",
      "key  1 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.0978164999965197\n",
      "Current Error err_H 0.0978164999965197\n",
      "myFeeder.t  1\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.37086773 0.37578195 0.32484725 ... 0.03111639 0.12732695 0.46366048]\n",
      " [0.41188773 0.36344951 0.30458248 ... 0.03024545 0.12266402 0.42599469]\n",
      " [0.41188773 0.36344951 0.30458248 ... 0.03024545 0.12266402 0.42599469]\n",
      " ...\n",
      " [0.         0.00442359 0.01578411 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00442359 0.01578411 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00442359 0.01578411 ... 0.01821061 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[5.79245398e-01 3.60321716e-01 3.36456212e-01 ... 3.10899974e-02\n",
      "  1.61829026e-01 5.12643678e-01]\n",
      " [5.86828105e-01 3.65534704e-01 3.40868975e-01 ... 3.53127474e-02\n",
      "  1.63961684e-01 5.20601238e-01]\n",
      " [5.87146089e-01 3.65921954e-01 3.41208418e-01 ... 3.53655318e-02\n",
      "  1.64046027e-01 5.20954907e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.76616026e-04 2.82416836e-02 ... 1.87384534e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.06404528e-04 2.68160217e-02 ... 1.86328847e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.06404528e-04 2.25390360e-02 ... 1.85801003e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "list_RMSE_SousModele  [0.10228659486082035, 0.05665463316641945] mean of list_RMSE_SousModele 0.0794706140136199\n",
      " RMSE resultat vote 0.05711970744512062\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  KNN\n",
      "key  0  value[6]  0.39107838594488675\n",
      "key  1  value[6]  0.5474158342212556\n",
      "key  2  value[6]  1.0\n",
      "key  0 value[2]  0.07985771565614098\n",
      "key  1 value[2]  0.43429431182386447\n",
      "key  2 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.07746810372082016\n",
      "Current Error err_H 0.05711970744512062\n",
      "myFeeder.t  2\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00446828 0.01578411 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00446828 0.01578411 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00580876 0.01476578 ... 0.01821061 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00920465 0.01608961 ... 0.01916073 0.         0.        ]\n",
      " [0.         0.00612154 0.01496945 ... 0.01860649 0.         0.        ]\n",
      " [0.         0.00612154 0.01507128 ... 0.01860649 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00047662 0.02111337 ... 0.01868567 0.         0.        ]\n",
      " [0.         0.00047662 0.0245757  ... 0.01852732 0.         0.        ]\n",
      " [0.         0.00053619 0.02939579 ... 0.01879124 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.01900883 ... 0.02179995 0.         0.        ]\n",
      " [0.         0.00047662 0.01832994 ... 0.02211665 0.         0.        ]\n",
      " [0.         0.00044683 0.01900883 ... 0.02185273 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00047662 0.02559403 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00053619 0.02552614 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00053619 0.02681602 ... 0.019583   0.         0.        ]\n",
      " ...\n",
      " [0.         0.00122133 0.01934827 ... 0.0178939  0.         0.        ]\n",
      " [0.         0.00122133 0.01948405 ... 0.01794669 0.         0.        ]\n",
      " [0.         0.00119154 0.01948405 ... 0.01784112 0.         0.        ]]\n",
      "list_RMSE_SousModele  [0.1029954319281932, 0.06015379098027394, 0.06858307185043783] mean of list_RMSE_SousModele 0.07724409825296832\n",
      " RMSE resultat vote 0.06046588525085977\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  Tree\n",
      "key  0  value[6]  0.3081780004228992\n",
      "key  1  value[6]  0.39107838594488675\n",
      "key  2  value[6]  0.5474158342212556\n",
      "key  3  value[6]  1.0\n",
      "key  0 value[2]  0.06267430892393212\n",
      "key  1 value[2]  0.2594691553905873\n",
      "key  2 value[2]  0.5173389125160672\n",
      "key  3 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.0718006975641667\n",
      "Current Error err_H 0.06046588525085977\n",
      "myFeeder.t  3\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00616622 0.01547862 ... 0.01868567 0.         0.        ]\n",
      " [0.         0.00482574 0.01649695 ... 0.01908155 0.         0.        ]\n",
      " [0.         0.00482574 0.01649695 ... 0.01908155 0.         0.        ]\n",
      " ...\n",
      " [0.45417355 0.28065237 0.24246436 ... 0.02937451 0.09277065 0.38912467]\n",
      " [0.50827371 0.32810545 0.3092668  ... 0.0314331  0.11295861 0.43050398]\n",
      " [0.50576041 0.34244861 0.32046843 ... 0.03159145 0.12344117 0.44217507]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.46827525e-04 2.05023761e-02 ... 2.19055160e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.36193029e-04 2.12491514e-02 ... 2.20638691e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.04344874e-02 ... 2.20110847e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.57701951e-01 3.28060769e-01 3.19076714e-01 ... 2.93481130e-02\n",
      "  1.94047834e-01 4.41909814e-01]\n",
      " [6.59940072e-01 3.28388442e-01 3.18397828e-01 ... 2.94008973e-02\n",
      "  1.93734562e-01 4.44385500e-01]\n",
      " [6.39907051e-01 3.25141495e-01 3.09572301e-01 ... 2.88730536e-02\n",
      "  1.93734562e-01 4.40671972e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00113196 0.01995927 ... 0.01794669 0.         0.        ]\n",
      " [0.         0.00122133 0.01955193 ... 0.01784112 0.         0.        ]\n",
      " [0.         0.00128091 0.01948405 ... 0.01784112 0.         0.        ]\n",
      " ...\n",
      " [0.76699077 0.32654155 0.29049559 ... 0.03050937 0.20071089 0.46560566]\n",
      " [0.75637498 0.32868633 0.28221317 ... 0.03050937 0.19909633 0.46595933]\n",
      " [0.75754907 0.33270777 0.2706721  ... 0.03230404 0.19677089 0.49142352]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.46827525e-04 2.85132383e-02 ... 2.45447348e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.74949084e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.74949084e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.77472023e-01 3.69973190e-01 3.42158859e-01 ... 3.56294537e-02\n",
      "  1.97542021e-01 5.09283820e-01]\n",
      " [7.77472023e-01 3.69973190e-01 3.42158859e-01 ... 3.56294537e-02\n",
      "  1.97542021e-01 5.09283820e-01]\n",
      " [7.77472023e-01 3.69973190e-01 3.42158859e-01 ... 3.56294537e-02\n",
      "  1.97542021e-01 5.09283820e-01]]\n",
      "list_RMSE_SousModele  [0.12498707046656875, 0.07376921430269853, 0.08151726427502883, 0.08299111035586103] mean of list_RMSE_SousModele 0.09081616485003928\n",
      " RMSE resultat vote 0.06830660311427017\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  KNN\n",
      "key  0  value[6]  0.25465259711919624\n",
      "key  1  value[6]  0.3081780004228992\n",
      "key  2  value[6]  0.39107838594488675\n",
      "key  3  value[6]  0.5474158342212556\n",
      "key  4  value[6]  1.0\n",
      "key  0 value[2]  0.05813699179268714\n",
      "key  1 value[2]  0.19489209689901688\n",
      "key  2 value[2]  0.35642845253735483\n",
      "key  3 value[2]  0.5895909520705518\n",
      "key  4 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.07092717395169257\n",
      "Current Error err_H 0.06830660311427017\n",
      "myFeeder.t  4\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.50537516 0.34428061 0.32454175 ... 0.03222486 0.12103741 0.44960212]\n",
      " [0.50689782 0.35125112 0.32729124 ... 0.03159145 0.12053136 0.4469496 ]\n",
      " [0.51808842 0.34557641 0.32209776 ... 0.03159145 0.11718778 0.43952255]\n",
      " ...\n",
      " [0.         0.00983021 0.01181263 ... 0.01781473 0.         0.        ]\n",
      " [0.         0.00710456 0.01334012 ... 0.01797308 0.         0.        ]\n",
      " [0.         0.00969616 0.01221996 ... 0.01828979 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[6.16951018e-01 3.20226393e-01 2.99185336e-01 ... 2.78701504e-02\n",
      "  1.93288752e-01 4.43678161e-01]\n",
      " [6.16951018e-01 3.20226393e-01 2.99185336e-01 ... 2.78701504e-02\n",
      "  1.93288752e-01 4.43678161e-01]\n",
      " [6.18296337e-01 3.23056300e-01 2.99049559e-01 ... 2.78701504e-02\n",
      "  1.92951383e-01 4.50751547e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.76616026e-04 2.62050238e-02 ... 1.92135128e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.06404528e-04 2.60013578e-02 ... 1.92135128e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 2.58655804e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.56313826e-01 3.41257075e-01 2.79497624e-01 ... 3.25679599e-02\n",
      "  1.94987650e-01 5.00618921e-01]\n",
      " [7.56313826e-01 3.41257075e-01 2.79497624e-01 ... 3.25679599e-02\n",
      "  1.94987650e-01 5.00618921e-01]\n",
      " [7.56313826e-01 3.41257075e-01 2.79497624e-01 ... 3.25679599e-02\n",
      "  1.94987650e-01 5.00618921e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.46827525e-04 2.81737950e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.83774610e-02 ... 2.07442597e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.81737950e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.77472023e-01 3.69973190e-01 3.42158859e-01 ... 3.56294537e-02\n",
      "  1.97542021e-01 5.09283820e-01]\n",
      " [7.77472023e-01 3.69973190e-01 3.42158859e-01 ... 3.56294537e-02\n",
      "  1.97542021e-01 5.09283820e-01]\n",
      " [7.77472023e-01 3.69973190e-01 3.42158859e-01 ... 3.56294537e-02\n",
      "  1.97542021e-01 5.09283820e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.46827525e-04 2.54582485e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.54582485e-02 ... 2.21694378e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.54582485e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.61462729e-01 3.42686923e-01 3.42158859e-01 ... 3.48376880e-02\n",
      "  1.99096331e-01 4.38019452e-01]\n",
      " [7.60594386e-01 3.36103664e-01 3.33401222e-01 ... 3.48904724e-02\n",
      "  1.98361347e-01 4.38373121e-01]\n",
      " [7.72127438e-01 3.33899315e-01 3.30957230e-01 ... 3.50488255e-02\n",
      "  1.98144467e-01 4.36604775e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.46827525e-04 1.54107264e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 1.54107264e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 1.54786151e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "list_RMSE_SousModele  [0.1109935535520973, 0.09137311316122942, 0.09959993323386462, 0.12707450689999622, 0.09868813002181015] mean of list_RMSE_SousModele 0.10554584737379953\n",
      " RMSE resultat vote 0.09086624176295696\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  R_Forest\n",
      "key  0  value[6]  0.21615527050978905\n",
      "key  1  value[6]  0.25465259711919624\n",
      "key  2  value[6]  0.3081780004228992\n",
      "key  3  value[6]  0.39107838594488675\n",
      "key  4  value[6]  0.5474158342212556\n",
      "key  5  value[6]  1.0\n",
      "key  0 value[2]  0.0510486075963949\n",
      "key  1 value[2]  0.14356443815348044\n",
      "key  2 value[2]  0.25213556964289846\n",
      "key  3 value[2]  0.3939282632381201\n",
      "key  4 value[2]  0.6113773790919804\n",
      "key  5 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.07491498751394546\n",
      "Current Error err_H 0.09086624176295696\n",
      "myFeeder.t  5\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00701519 0.01272912 ... 0.01662708 0.         0.        ]\n",
      " [0.         0.00701519 0.01283096 ... 0.01694378 0.         0.        ]\n",
      " [0.         0.00571939 0.01354379 ... 0.01733967 0.         0.        ]\n",
      " ...\n",
      " [0.47549074 0.36184093 0.3107943  ... 0.03024545 0.12457979 0.45809019]\n",
      " [0.47710512 0.36233244 0.31232179 ... 0.03024545 0.12461594 0.46127321]\n",
      " [0.51234636 0.36103664 0.30397149 ... 0.02929533 0.12239292 0.46419098]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 5.65981531e-04 2.28784793e-02 ... 1.87384534e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.00950441e-02 ... 1.84745315e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 1.96877122e-02 ... 1.85273159e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.90166942e-01 3.51921358e-01 3.28716904e-01 ... 2.77117973e-02\n",
      "  1.89312609e-01 5.01503095e-01]\n",
      " [5.84638904e-01 3.52874590e-01 3.38628649e-01 ... 2.77117973e-02\n",
      "  1.88204109e-01 5.01326260e-01]\n",
      " [6.27848101e-01 3.53500149e-01 3.31093007e-01 ... 2.97703880e-02\n",
      "  1.82203747e-01 4.94960212e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.76616026e-04 2.80380177e-02 ... 2.04803378e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 2.84453496e-02 ... 2.07442597e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 2.84453496e-02 ... 2.07442597e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.61945820e-01 3.65802800e-01 3.43312967e-01 ... 2.87147004e-02\n",
      "  1.82697753e-01 5.18656057e-01]\n",
      " [7.01363664e-01 3.65832589e-01 3.58587916e-01 ... 2.81868567e-02\n",
      "  1.93312850e-01 5.15119363e-01]\n",
      " [7.67749037e-01 3.57640751e-01 3.32111337e-01 ... 2.85563473e-02\n",
      "  1.92553768e-01 5.12466844e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.46827525e-04 2.54582485e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.64765784e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.54582485e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.09209319e-01 3.84718499e-01 3.27902240e-01 ... 3.56294537e-02\n",
      "  1.99530092e-01 4.77453581e-01]\n",
      " [7.67565584e-01 3.57908847e-01 3.53360489e-01 ... 3.80047506e-02\n",
      "  1.89589734e-01 6.31299735e-01]\n",
      " [7.18033388e-01 3.54334227e-01 3.45213849e-01 ... 3.48376880e-02\n",
      "  1.89047533e-01 5.43766578e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.76616026e-04 1.77189409e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 1.83978276e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 1.98913781e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.94478077e-01 3.60023831e-01 3.38085540e-01 ... 3.56822381e-02\n",
      "  1.97602265e-01 4.90893015e-01]\n",
      " [6.92961536e-01 3.57223712e-01 3.28309572e-01 ... 3.54183162e-02\n",
      "  1.96385324e-01 4.80636605e-01]\n",
      " [6.57555189e-01 3.58951445e-01 3.37270876e-01 ... 3.40987068e-02\n",
      "  1.96325080e-01 4.29354553e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 6.25558534e-04 2.58655804e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 6.25558534e-04 2.54582485e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.36193029e-04 2.54582485e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.89469822e-01 3.62689902e-01 3.71894094e-01 ... 3.18289786e-02\n",
      "  1.97523947e-01 4.28647215e-01]\n",
      " [7.76958356e-01 3.60902592e-01 3.67515275e-01 ... 3.31749802e-02\n",
      "  1.94849087e-01 4.22015915e-01]\n",
      " [6.63236103e-01 3.61260054e-01 3.59674134e-01 ... 3.28582740e-02\n",
      "  1.30489789e-01 4.06100796e-01]]\n",
      "list_RMSE_SousModele  [0.09902474262139661, 0.07362281360063773, 0.08298875328414806, 0.10614850309644978, 0.08214175400804268, 0.057528440473668147] mean of list_RMSE_SousModele 0.08357583451405719\n",
      " RMSE resultat vote 0.05868344366031848\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  Tree\n",
      "key  0  value[6]  0.18670485439918758\n",
      "key  1  value[6]  0.21615527050978905\n",
      "key  2  value[6]  0.25465259711919624\n",
      "key  3  value[6]  0.3081780004228992\n",
      "key  4  value[6]  0.39107838594488675\n",
      "key  5  value[6]  0.5474158342212556\n",
      "key  6  value[6]  1.0\n",
      "key  0 value[2]  0.04663790260757047\n",
      "key  1 value[2]  0.11975169869498177\n",
      "key  2 value[2]  0.20275032376073315\n",
      "key  3 value[2]  0.30570951977976074\n",
      "key  4 value[2]  0.445467336746208\n",
      "key  5 value[2]  0.6454370398553199\n",
      "key  6 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.07220973020500762\n",
      "Current Error err_H 0.05868344366031848\n",
      "myFeeder.t  6\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.41784994 0.35317248 0.32057026 ... 0.02913698 0.11380806 0.45596817]\n",
      " [0.40209136 0.36000894 0.31354379 ... 0.02834521 0.12445328 0.44535809]\n",
      " [0.40418272 0.36724754 0.32260692 ... 0.02921615 0.10853063 0.44880637]\n",
      " ...\n",
      " [0.         0.06148347 0.049389   ... 0.02755344 0.         0.00371353]\n",
      " [0.09464318 0.18552279 0.15397149 ... 0.02747427 0.04259895 0.21538462]\n",
      " [0.13880022 0.16983914 0.13788187 ... 0.02676168 0.03632749 0.17453581]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.58345258 0.35251713 0.34175153 ... 0.02713117 0.18803542 0.49496021]\n",
      " [0.60374243 0.35117665 0.33102512 ... 0.02744788 0.18231219 0.49867374]\n",
      " [0.58211949 0.35582365 0.34209097 ... 0.02845078 0.18132418 0.50044209]\n",
      " ...\n",
      " [0.         0.08087578 0.05485404 ... 0.02164159 0.         0.03607427]\n",
      " [0.         0.0515639  0.05302105 ... 0.0202692  0.         0.        ]\n",
      " [0.         0.11081323 0.0736592  ... 0.02370018 0.         0.04049514]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.6978903  0.35618111 0.31948405 ... 0.0294009  0.19139707 0.51547303]\n",
      " [0.69077234 0.36720286 0.33021045 ... 0.03188176 0.17728779 0.51264368]\n",
      " [0.6140647  0.36389634 0.33496266 ... 0.02760623 0.18297488 0.5158267 ]\n",
      " ...\n",
      " [0.         0.05504915 0.04582485 ... 0.02074426 0.         0.06949602]\n",
      " [0.         0.05406613 0.03815343 ... 0.02016363 0.         0.07869142]\n",
      " [0.         0.01546023 0.03557366 ... 0.02011085 0.         0.01114058]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.71803339 0.35433423 0.34521385 ... 0.03483769 0.18904753 0.54376658]\n",
      " [0.73124197 0.35924933 0.35437882 ... 0.0253365  0.19121634 0.51458886]\n",
      " [0.58924968 0.36729223 0.3604888  ... 0.03483769 0.19284294 0.5464191 ]\n",
      " ...\n",
      " [0.         0.16979446 0.01323829 ... 0.02612827 0.         0.28912467]\n",
      " [0.         0.12868633 0.13238289 ... 0.02692003 0.         0.10079576]\n",
      " [0.         0.11260054 0.16089613 ... 0.03087886 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.65755519 0.35895144 0.33727088 ... 0.03409871 0.19632508 0.42935455]\n",
      " [0.6175503  0.36032172 0.32980312 ... 0.03430984 0.19425267 0.44756852]\n",
      " [0.59320002 0.36026214 0.33849287 ... 0.03077329 0.19696367 0.49531388]\n",
      " ...\n",
      " [0.         0.01912422 0.02437203 ... 0.02185273 0.         0.04562334]\n",
      " [0.         0.08084599 0.04928717 ... 0.02950647 0.         0.1734748 ]\n",
      " [0.         0.0629431  0.07033265 ... 0.02596991 0.         0.0489832 ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.67033572 0.35786416 0.36262729 ... 0.02929533 0.19455991 0.43925729]\n",
      " [0.61212622 0.35665773 0.36924644 ... 0.03056215 0.19472257 0.44190981]\n",
      " [0.56751055 0.35183199 0.35213849 ... 0.03111639 0.17363094 0.43793103]\n",
      " ...\n",
      " [0.         0.07756926 0.05977597 ... 0.02612827 0.         0.02201592]\n",
      " [0.01478628 0.04544236 0.05234216 ... 0.02438638 0.00249413 0.03156499]\n",
      " [0.         0.05589812 0.05305499 ... 0.02921615 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.78022381 0.36595174 0.36659878 ... 0.03167063 0.19266221 0.43766578]\n",
      " [0.60557696 0.38069705 0.34725051 ... 0.02850356 0.19230074 0.41644562]\n",
      " [0.42836177 0.37488829 0.34826884 ... 0.03483769 0.189409   0.4403183 ]\n",
      " ...\n",
      " [0.         0.15728329 0.02545825 ... 0.02058591 0.         0.14323607]\n",
      " [0.         0.04736372 0.08248473 ... 0.02850356 0.         0.        ]\n",
      " [0.         0.02412869 0.03360489 ... 0.02850356 0.         0.        ]]\n",
      "list_RMSE_SousModele  [0.10094610657953891, 0.07944626661883994, 0.08652845739173323, 0.12150876934794508, 0.08707908957509854, 0.07223593248458965, 0.08227925008244709] mean of list_RMSE_SousModele 0.09000341029717034\n",
      " RMSE resultat vote 0.06357572030436644\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  R_Forest\n",
      "key  0  value[6]  0.16334850821192484\n",
      "key  1  value[6]  0.18670485439918758\n",
      "key  2  value[6]  0.21615527050978905\n",
      "key  3  value[6]  0.25465259711919624\n",
      "key  4  value[6]  0.3081780004228992\n",
      "key  5  value[6]  0.39107838594488675\n",
      "key  6  value[6]  0.5474158342212556\n",
      "key  7  value[6]  1.0\n",
      "key  0 value[2]  0.04498693495201278\n",
      "key  1 value[2]  0.10456610705480024\n",
      "key  2 value[2]  0.1710517508449157\n",
      "key  3 value[2]  0.25005766137061813\n",
      "key  4 value[2]  0.352598366308954\n",
      "key  5 value[2]  0.48212079758394294\n",
      "key  6 value[2]  0.6656039577214671\n",
      "key  7 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.07097630021920173\n",
      "Current Error err_H 0.06357572030436644\n",
      "myFeeder.t  7\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.09030384 0.0808554  ... 0.03167063 0.         0.00371353]\n",
      " [0.         0.1023235  0.07596741 ... 0.02953286 0.         0.066313  ]\n",
      " [0.         0.11081323 0.06965377 ... 0.02874109 0.         0.04005305]\n",
      " ...\n",
      " [0.         0.12001787 0.07107943 ... 0.02897862 0.         0.08992042]\n",
      " [0.         0.12001787 0.07107943 ... 0.02897862 0.         0.08992042]\n",
      " [0.         0.12001787 0.07107943 ... 0.02897862 0.         0.08992042]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.09862973 0.06171079 ... 0.02501979 0.         0.06525199]\n",
      " [0.         0.03997617 0.04344874 ... 0.02660333 0.         0.        ]\n",
      " [0.         0.00643432 0.02973523 ... 0.01821061 0.         0.        ]\n",
      " ...\n",
      " [0.         0.0041406  0.02851324 ... 0.01847453 0.         0.        ]\n",
      " [0.         0.0041406  0.02851324 ... 0.01847453 0.         0.        ]\n",
      " [0.         0.0041406  0.02851324 ... 0.01847453 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.01432827 0.02708758 ... 0.01979414 0.         0.01962865]\n",
      " [0.         0.00330652 0.02016293 ... 0.01979414 0.         0.01591512]\n",
      " [0.         0.08275246 0.03007468 ... 0.0280285  0.         0.23996463]\n",
      " ...\n",
      " [0.         0.00068514 0.01934827 ... 0.01905516 0.         0.        ]\n",
      " [0.         0.00068514 0.01934827 ... 0.01905516 0.         0.        ]\n",
      " [0.         0.00068514 0.01982349 ... 0.01884402 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.02725648 0.01323829 ... 0.01821061 0.         0.29442971]\n",
      " [0.         0.16934763 0.01323829 ... 0.02612827 0.         0.28912467]\n",
      " [0.         0.01653262 0.00610998 ... 0.02375297 0.         0.14323607]\n",
      " ...\n",
      " [0.         0.00044683 0.00509165 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.00509165 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.00509165 ... 0.01821061 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.02114984 0.03441955 ... 0.02443917 0.         0.02528736]\n",
      " [0.         0.02147751 0.02600136 ... 0.02206387 0.         0.03076923]\n",
      " [0.         0.00044683 0.02410048 ... 0.02216944 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.02267481 ... 0.02253893 0.         0.        ]\n",
      " [0.         0.00044683 0.02267481 ... 0.02253893 0.         0.        ]\n",
      " [0.         0.00044683 0.02267481 ... 0.02253893 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.07287757 0.09195519 ... 0.02747427 0.         0.        ]\n",
      " [0.00792515 0.07292225 0.07433809 ... 0.02897862 0.00131936 0.        ]\n",
      " [0.04443221 0.05013405 0.06242363 ... 0.02486144 0.00276523 0.04774536]\n",
      " ...\n",
      " [0.04208402 0.05183199 0.05346232 ... 0.02549485 0.00972348 0.05013263]\n",
      " [0.04208402 0.05183199 0.05346232 ... 0.02549485 0.00972348 0.05013263]\n",
      " [0.04208402 0.05183199 0.05346232 ... 0.02549485 0.00972348 0.05013263]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.09651475 0.02342159 ... 0.02454473 0.         0.        ]\n",
      " [0.         0.14075067 0.12423625 ... 0.03483769 0.         0.        ]\n",
      " [0.         0.07596068 0.04378819 ... 0.02216944 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.02647658 ... 0.02058591 0.         0.        ]\n",
      " [0.         0.00044683 0.02647658 ... 0.02058591 0.         0.        ]\n",
      " [0.         0.00044683 0.02647658 ... 0.02058591 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.06854334 0.06313646 ... 0.02216944 0.         0.01671088]\n",
      " [0.00671436 0.10714924 0.08014257 ... 0.02494062 0.00113862 0.00689655]\n",
      " [0.0253348  0.06756032 0.05875764 ... 0.02256532 0.00133743 0.01750663]\n",
      " ...\n",
      " [0.         0.01724754 0.04348269 ... 0.02074426 0.         0.06206897]\n",
      " [0.         0.01563896 0.04246436 ... 0.02019002 0.         0.04535809]\n",
      " [0.         0.01563896 0.04246436 ... 0.02019002 0.         0.04535809]]\n",
      "list_RMSE_SousModele  [0.10928437249136197, 0.07949888135792506, 0.08112009835242108, 0.11373038444370068, 0.08137288445109765, 0.09046791368212473, 0.09748616453456754, 0.06973685643933993] mean of list_RMSE_SousModele 0.09033719446906732\n",
      " RMSE resultat vote 0.06502115157992558\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  KNN\n",
      "key  0  value[6]  0.1444116730248319\n",
      "key  1  value[6]  0.16334850821192484\n",
      "key  2  value[6]  0.18670485439918758\n",
      "key  3  value[6]  0.21615527050978905\n",
      "key  4  value[6]  0.25465259711919624\n",
      "key  5  value[6]  0.3081780004228992\n",
      "key  6  value[6]  0.39107838594488675\n",
      "key  7  value[6]  0.5474158342212556\n",
      "key  8  value[6]  1.0\n",
      "key  0 value[2]  0.04415082444381604\n",
      "key  1 value[2]  0.09515694394427715\n",
      "key  2 value[2]  0.15064733926314905\n",
      "key  3 value[2]  0.21449468731354873\n",
      "key  4 value[2]  0.2925294180366545\n",
      "key  5 value[2]  0.3858939833613157\n",
      "key  6 value[2]  0.51096003167839\n",
      "key  7 value[2]  0.6879084113585586\n",
      "key  8 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.07023190663929221\n",
      "Current Error err_H 0.06502115157992558\n",
      "myFeeder.t  8\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.12001787 0.07107943 ... 0.02897862 0.         0.08992042]\n",
      " [0.         0.12001787 0.07107943 ... 0.02897862 0.         0.08992042]\n",
      " [0.         0.12001787 0.07107943 ... 0.02897862 0.         0.08992042]\n",
      " ...\n",
      " [0.50862227 0.3590706  0.31232179 ... 0.02850356 0.11393457 0.43103448]\n",
      " [0.47958173 0.35321716 0.31680244 ... 0.02977039 0.10966926 0.42997347]\n",
      " [0.4907173  0.33659517 0.29490835 ... 0.02897862 0.1108621  0.41007958]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.0041406  0.02851324 ... 0.01847453 0.         0.        ]\n",
      " [0.         0.0041406  0.02851324 ... 0.01847453 0.         0.        ]\n",
      " [0.         0.0041406  0.02817379 ... 0.01847453 0.         0.        ]\n",
      " ...\n",
      " [0.58944536 0.3536193  0.33021045 ... 0.02792293 0.18867402 0.50044209]\n",
      " [0.60657983 0.35171284 0.3353021  ... 0.02787015 0.18210736 0.49708223]\n",
      " [0.60560142 0.32892464 0.32443992 ... 0.02829243 0.18937285 0.46878868]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 6.85135538e-04 1.98234895e-02 ... 1.88440222e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 6.85135538e-04 1.93482688e-02 ... 1.90551597e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 6.25558534e-04 1.92803802e-02 ... 1.93190816e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.45979331e-01 3.44682752e-01 3.14799728e-01 ... 3.13011349e-02\n",
      "  1.94445449e-01 4.92307692e-01]\n",
      " [7.24894515e-01 3.47065833e-01 3.08961303e-01 ... 3.10372130e-02\n",
      "  1.94505693e-01 4.94076039e-01]\n",
      " [7.06671559e-01 3.63747394e-01 3.23217923e-01 ... 3.15650567e-02\n",
      "  1.93806856e-01 5.10698497e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.46827525e-04 5.09164969e-03 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 5.09164969e-03 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 5.09164969e-03 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.20968630e-01 2.07774799e-01 9.77596741e-02 ... 3.08788599e-02\n",
      "  0.00000000e+00 3.05039788e-01]\n",
      " [7.20968630e-01 2.07774799e-01 9.77596741e-02 ... 3.08788599e-02\n",
      "  0.00000000e+00 3.05039788e-01]\n",
      " [7.61144744e-01 3.47631814e-01 2.97352342e-01 ... 3.24623911e-02\n",
      "  1.94288813e-01 4.82758621e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.46827525e-04 2.26748133e-02 ... 2.25389285e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.26748133e-02 ... 2.25389285e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.26748133e-02 ... 2.25389285e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.04665811e-01 3.05064045e-01 3.03394433e-01 ... 3.17234099e-02\n",
      "  1.82818242e-01 4.64544651e-01]\n",
      " [6.98770868e-01 3.46708371e-01 3.36320434e-01 ... 3.28318818e-02\n",
      "  1.95409362e-01 4.68258179e-01]\n",
      " [7.44046964e-01 3.58921656e-01 3.36048880e-01 ... 3.13011349e-02\n",
      "  1.96060004e-01 4.86295314e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.04208402 0.05183199 0.05346232 ... 0.02549485 0.00972348 0.05013263]\n",
      " [0.04208402 0.05183199 0.05346232 ... 0.02549485 0.00972348 0.05013263]\n",
      " [0.04208402 0.05183199 0.05346232 ... 0.02549485 0.00972348 0.05013263]\n",
      " ...\n",
      " [0.71539167 0.35469169 0.36547862 ... 0.03238321 0.18366167 0.43952255]\n",
      " [0.63447074 0.31689008 0.31904277 ... 0.03135392 0.17776975 0.48435013]\n",
      " [0.70869565 0.33686327 0.34276986 ... 0.04117181 0.17091993 0.42307692]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.46827525e-04 2.64765784e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.64765784e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.64765784e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.05925518e-01 3.49865952e-01 3.42158859e-01 ... 3.08788599e-02\n",
      "  1.84890656e-01 4.13793103e-01]\n",
      " [7.56374977e-01 3.70420018e-01 3.77800407e-01 ... 3.56294537e-02\n",
      "  9.01861558e-02 4.37665782e-01]\n",
      " [7.71968446e-01 3.77569258e-01 4.37881874e-01 ... 2.85035629e-02\n",
      "  1.89047533e-01 4.42970822e-01]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.01724754 0.04348269 ... 0.02074426 0.         0.06206897]\n",
      " [0.         0.01724754 0.04348269 ... 0.02074426 0.         0.06206897]\n",
      " [0.         0.01563896 0.04246436 ... 0.02019002 0.         0.04535809]\n",
      " ...\n",
      " [0.73432398 0.34365505 0.31558045 ... 0.03460016 0.15590096 0.42175066]\n",
      " [0.68866263 0.34579982 0.3287169  ... 0.03452098 0.15875655 0.43740053]\n",
      " [0.55534764 0.30183199 0.24725051 ... 0.03293745 0.13898428 0.33474801]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 4.46827525e-04 3.97827563e-02 ... 2.25917129e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 3.96469790e-02 ... 2.26972816e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 3.95112016e-02 ... 2.25917129e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.88081698e-01 3.53053321e-01 3.50848608e-01 ... 3.33069411e-02\n",
      "  9.28851136e-02 4.27055703e-01]\n",
      " [7.01400355e-01 3.41971999e-01 3.37067210e-01 ... 3.48904724e-02\n",
      "  9.29333092e-02 4.21927498e-01]\n",
      " [7.31963554e-01 3.48853143e-01 3.49626612e-01 ... 3.30430193e-02\n",
      "  1.04982228e-01 4.37135279e-01]]\n",
      "list_RMSE_SousModele  [0.1121824546961685, 0.08219104799967224, 0.07514237891082819, 0.12121235544287078, 0.08022931611062804, 0.10178510563433657, 0.11041910126544416, 0.07456070717105473, 0.060719834898585526] mean of list_RMSE_SousModele 0.09093803356995431\n",
      " RMSE resultat vote 0.06314727359433357\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  R_Forest\n",
      "key  0  value[6]  0.1288294285628787\n",
      "key  1  value[6]  0.1444116730248319\n",
      "key  2  value[6]  0.16334850821192484\n",
      "key  3  value[6]  0.18670485439918758\n",
      "key  4  value[6]  0.21615527050978905\n",
      "key  5  value[6]  0.25465259711919624\n",
      "key  6  value[6]  0.3081780004228992\n",
      "key  7  value[6]  0.39107838594488675\n",
      "key  8  value[6]  0.5474158342212556\n",
      "key  9  value[6]  1.0\n",
      "key  0 value[2]  0.04079844544857375\n",
      "key  1 value[2]  0.08335241493571893\n",
      "key  2 value[2]  0.12920790363329082\n",
      "key  3 value[2]  0.1807463612381992\n",
      "key  4 value[2]  0.24330428265415413\n",
      "key  5 value[2]  0.31514190841005746\n",
      "key  6 value[2]  0.407870739258303\n",
      "key  7 value[2]  0.5291542692972505\n",
      "key  8 value[2]  0.702107300111225\n",
      "key  9 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.06944472518985237\n",
      "Current Error err_H 0.06314727359433357\n",
      "myFeeder.t  9\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.46173179 0.33905273 0.28961303 ... 0.02953286 0.10144587 0.40238727]\n",
      " [0.47042744 0.34955317 0.29653768 ... 0.02826603 0.10800651 0.39787798]\n",
      " [0.48767199 0.36831993 0.31099796 ... 0.02787015 0.11444063 0.4198939 ]\n",
      " ...\n",
      " [0.         0.00853441 0.01323829 ... 0.01773555 0.         0.        ]\n",
      " [0.         0.00853441 0.01323829 ... 0.01773555 0.         0.        ]\n",
      " [0.         0.00853441 0.01323829 ... 0.01773555 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[6.33486210e-01 3.23056300e-01 3.15071283e-01 ... 2.87674848e-02\n",
      "  1.89927104e-01 4.57471264e-01]\n",
      " [7.36843393e-01 3.35597259e-01 3.43448744e-01 ... 3.44154130e-02\n",
      "  1.86673896e-01 4.63837312e-01]\n",
      " [7.36843393e-01 3.35597259e-01 3.43448744e-01 ... 3.44154130e-02\n",
      "  1.86673896e-01 4.63837312e-01]\n",
      " ...\n",
      " [0.00000000e+00 5.36193029e-04 1.46639511e-02 ... 1.77355503e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.06404528e-04 1.45960625e-02 ... 1.76827659e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.36193029e-04 1.46639511e-02 ... 1.77355503e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.32929738e-01 3.54632112e-01 3.09164969e-01 ... 3.14594880e-02\n",
      "  1.91818784e-01 5.03625111e-01]\n",
      " [7.53782181e-01 3.32588621e-01 3.00882553e-01 ... 3.16706255e-02\n",
      "  1.94120128e-01 4.90008842e-01]\n",
      " [7.56179294e-01 3.32290736e-01 2.96334012e-01 ... 3.23040380e-02\n",
      "  1.93638171e-01 4.94783378e-01]\n",
      " ...\n",
      " [0.00000000e+00 5.06404528e-04 2.40325866e-02 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.06404528e-04 2.35573659e-02 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.06404528e-04 2.40325866e-02 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.73069162e-01 3.85612154e-01 3.29938900e-01 ... 3.48376880e-02\n",
      "  1.98807157e-01 4.69496021e-01]\n",
      " [7.55641167e-01 3.60589812e-01 3.36048880e-01 ... 3.24623911e-02\n",
      "  1.96276884e-01 4.93368700e-01]\n",
      " [7.75454045e-01 3.55674710e-01 3.17718941e-01 ... 3.56294537e-02\n",
      "  1.98807157e-01 4.88063660e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.46827525e-04 5.09164969e-03 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 5.09164969e-03 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 5.09164969e-03 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.47618174e-01 3.50193625e-01 3.38560760e-01 ... 3.13539192e-02\n",
      "  1.94951503e-01 4.86472149e-01]\n",
      " [7.56215985e-01 3.52100089e-01 3.26816022e-01 ... 3.43626287e-02\n",
      "  1.93806856e-01 4.44916004e-01]\n",
      " [7.53769950e-01 3.55704498e-01 3.26069246e-01 ... 3.51016099e-02\n",
      "  1.93481535e-01 4.40318302e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.46827525e-04 2.08418194e-02 ... 2.10609660e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 2.02308215e-02 ... 2.10081816e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.08418194e-02 ... 2.12721035e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.27682994e-01 3.37176050e-01 3.47556008e-01 ... 3.17498021e-02\n",
      "  1.81312127e-01 4.19363395e-01]\n",
      " [7.51715282e-01 3.41063450e-01 3.67820774e-01 ... 2.90577989e-02\n",
      "  1.95608169e-01 4.02652520e-01]\n",
      " [7.50192625e-01 3.23369080e-01 3.60590631e-01 ... 2.89786223e-02\n",
      "  1.94939454e-01 3.86206897e-01]\n",
      " ...\n",
      " [0.00000000e+00 5.36193029e-04 2.62729124e-02 ... 2.01108472e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.36193029e-04 2.62729124e-02 ... 2.01108472e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.36193029e-04 2.72912424e-02 ... 2.09026128e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.59677123e-01 3.40929401e-01 3.61507128e-01 ... 2.69200317e-02\n",
      "  1.93204410e-01 4.32360743e-01]\n",
      " [6.05026601e-01 3.73994638e-01 3.62525458e-01 ... 3.48376880e-02\n",
      "  8.98246882e-02 4.37665782e-01]\n",
      " [7.48119611e-01 3.48525469e-01 3.12627291e-01 ... 2.69200317e-02\n",
      "  1.94108079e-01 4.29708223e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.46827525e-04 2.64765784e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.64765784e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.64765784e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[6.71179600e-01 3.26139410e-01 3.15274949e-01 ... 3.35708630e-02\n",
      "  1.79540936e-01 3.67639257e-01]\n",
      " [7.26545588e-01 3.61304736e-01 3.30753564e-01 ... 3.56294537e-02\n",
      "  1.39616844e-01 4.09549072e-01]\n",
      " [7.55457714e-01 3.53932082e-01 3.41038697e-01 ... 3.48376880e-02\n",
      "  1.89896982e-01 4.14588859e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.02144772e-04 2.43380855e-02 ... 2.01900238e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.02144772e-04 2.43380855e-02 ... 2.01900238e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 2.10008937e-03 2.63747454e-02 ... 1.97149644e-02\n",
      "  0.00000000e+00 1.69761273e-02]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.39277197e-01 3.46738159e-01 3.40325866e-01 ... 3.28846661e-02\n",
      "  9.93794807e-02 4.33244916e-01]\n",
      " [7.15232679e-01 3.53321418e-01 3.59809912e-01 ... 3.30430193e-02\n",
      "  9.20657871e-02 4.37842617e-01]\n",
      " [7.11355715e-01 3.59457849e-01 3.62525458e-01 ... 3.42042755e-02\n",
      "  9.28730646e-02 4.37842617e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.76616026e-04 2.70875764e-02 ... 1.88440222e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 2.66802444e-02 ... 1.88968065e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.76616026e-04 2.70875764e-02 ... 1.89495909e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[7.18400294e-01 3.55987489e-01 3.35336049e-01 ... 3.56294537e-02\n",
      "  1.77137177e-01 4.22811671e-01]\n",
      " [7.42652724e-01 3.61572833e-01 3.32790224e-01 ... 3.48376880e-02\n",
      "  1.87095608e-01 4.16710875e-01]\n",
      " [7.28930471e-01 3.63315460e-01 3.36150713e-01 ... 3.48376880e-02\n",
      "  1.88758359e-01 4.15649867e-01]\n",
      " ...\n",
      " [0.00000000e+00 4.46827525e-04 2.99389002e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 3.10590631e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 3.70672098e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "list_RMSE_SousModele  [0.11690900846084683, 0.07426611302382435, 0.0728577266843464, 0.1051735400624159, 0.07495233259379147, 0.11066071129657568, 0.11360949381925162, 0.08688890315128175, 0.06425138597908947, 0.06469144380132086] mean of list_RMSE_SousModele 0.08842606588727445\n",
      " RMSE resultat vote 0.061026288840658305\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  R_Forest\n",
      "key  0  value[6]  0.11586412658816056\n",
      "key  1  value[6]  0.1288294285628787\n",
      "key  2  value[6]  0.1444116730248319\n",
      "key  3  value[6]  0.16334850821192484\n",
      "key  4  value[6]  0.18670485439918758\n",
      "key  5  value[6]  0.21615527050978905\n",
      "key  6  value[6]  0.25465259711919624\n",
      "key  7  value[6]  0.3081780004228992\n",
      "key  8  value[6]  0.39107838594488675\n",
      "key  9  value[6]  0.5474158342212556\n",
      "key  10  value[6]  1.0\n",
      "key  0 value[2]  0.039306838742498774\n",
      "key  1 value[2]  0.07646112794962631\n",
      "key  2 value[2]  0.1157932804570845\n",
      "key  3 value[2]  0.15956644404871112\n",
      "key  4 value[2]  0.21045596326717006\n",
      "key  5 value[2]  0.2682022759660285\n",
      "key  6 value[2]  0.34123504736392685\n",
      "key  7 value[2]  0.4299624077906989\n",
      "key  8 value[2]  0.5462065466048419\n",
      "key  9 value[2]  0.7043760355728464\n",
      "key  10 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.06860288155493297\n",
      "Current Error err_H 0.061026288840658305\n",
      "myFeeder.t  10\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00047662 0.01459606 ... 0.0175772  0.         0.        ]\n",
      " [0.         0.0005064  0.01466395 ... 0.0175772  0.         0.        ]\n",
      " [0.         0.00047662 0.01568228 ... 0.0175772  0.         0.        ]\n",
      " ...\n",
      " [0.         0.00226393 0.01955193 ... 0.01810504 0.         0.        ]\n",
      " [0.         0.00047662 0.01907671 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.01446029 ... 0.01794669 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.0005064  0.02403259 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00065535 0.02247115 ... 0.01826339 0.         0.        ]\n",
      " [0.         0.00068514 0.02138493 ... 0.01821061 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00053619 0.02294637 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.02355737 ... 0.01937187 0.         0.        ]\n",
      " [0.         0.00047662 0.02124915 ... 0.01963579 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.00509165 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.00509165 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.00509165 ... 0.01741884 0.         0.        ]\n",
      " ...\n",
      " [0.         0.01697945 0.02545825 ... 0.01821061 0.         0.12201592]\n",
      " [0.         0.00089366 0.00509165 ... 0.01741884 0.         0.        ]\n",
      " [0.         0.00044683 0.00509165 ... 0.01821061 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00047662 0.02023082 ... 0.02100818 0.         0.        ]\n",
      " [0.         0.00044683 0.02267481 ... 0.02206387 0.         0.        ]\n",
      " [0.         0.00041704 0.02233537 ... 0.0219583  0.         0.        ]\n",
      " ...\n",
      " [0.         0.01111111 0.01588595 ... 0.0219583  0.         0.05729443]\n",
      " [0.         0.00253202 0.0185336  ... 0.01989971 0.         0.        ]\n",
      " [0.         0.00044683 0.02002716 ... 0.0192663  0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.04448725 0.05661305 0.05132383 ... 0.02327791 0.01333815 0.05039788]\n",
      " [0.04208402 0.0766756  0.06201629 ... 0.02391132 0.00972348 0.07161804]\n",
      " [0.04208402 0.0766756  0.06201629 ... 0.02391132 0.00972348 0.07161804]\n",
      " ...\n",
      " [0.         0.00044683 0.02535642 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00049151 0.02617108 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.02525458 ... 0.01844814 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.02647658 ... 0.02058591 0.         0.        ]\n",
      " [0.         0.00044683 0.02647658 ... 0.02058591 0.         0.        ]\n",
      " [0.         0.00044683 0.02647658 ... 0.02058591 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.02545825 ... 0.02058591 0.         0.        ]\n",
      " [0.         0.00044683 0.02342159 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.02342159 ... 0.01821061 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00210009 0.02657841 ... 0.01971496 0.         0.01697613]\n",
      " [0.         0.00044683 0.02657841 ... 0.02058591 0.         0.        ]\n",
      " [0.         0.01112601 0.02576375 ... 0.02019002 0.         0.        ]\n",
      " ...\n",
      " [0.02375711 0.05607685 0.02657841 ... 0.01908155 0.0035966  0.01671088]\n",
      " [0.01388736 0.0139857  0.03665988 ... 0.0192399  0.00133743 0.        ]\n",
      " [0.         0.00044683 0.02617108 ... 0.01828979 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.02776646 ... 0.01873845 0.         0.        ]\n",
      " [0.         0.00047662 0.02681602 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.02579769 ... 0.01894959 0.         0.        ]\n",
      " ...\n",
      " [0.         0.02365207 0.03217923 ... 0.01826339 0.         0.        ]\n",
      " [0.         0.03190349 0.03564155 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.017605   0.03048201 ... 0.01842175 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.00000000e+00 5.36193029e-04 3.70672098e-02 ... 1.90023753e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.46827525e-04 3.18737271e-02 ... 2.00316706e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 7.14924039e-04 3.42158859e-02 ... 2.04275534e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 9.15996425e-03 3.45213849e-02 ... 1.96357878e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.91510277e-04 3.06517312e-02 ... 2.05859066e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 8.93655049e-05 1.71079430e-02 ... 1.82106097e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.03075356 ... 0.01971496 0.         0.        ]\n",
      " [0.         0.00049151 0.02922607 ... 0.02114014 0.         0.        ]\n",
      " [0.         0.00049151 0.02983707 ... 0.02256532 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00701519 0.03370672 ... 0.01916073 0.         0.02625995]\n",
      " [0.         0.00540661 0.03452138 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.03075356 ... 0.01828979 0.         0.        ]]\n",
      "list_RMSE_SousModele  [0.07435809303772609, 0.07332444839768884, 0.11262929309735777, 0.07456459603406612, 0.10857999653573974, 0.11040561179546443, 0.08560370314113938, 0.06288729167441268, 0.05959426785246913, 0.05670555984187208] mean of list_RMSE_SousModele 0.08186528614079362\n",
      " RMSE resultat vote 0.053805017325911135\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  KNN\n",
      "key  1  value[6]  0.11586412658816056\n",
      "key  2  value[6]  0.1288294285628787\n",
      "key  3  value[6]  0.1444116730248319\n",
      "key  4  value[6]  0.16334850821192484\n",
      "key  5  value[6]  0.18670485439918758\n",
      "key  6  value[6]  0.21615527050978905\n",
      "key  7  value[6]  0.25465259711919624\n",
      "key  8  value[6]  0.3081780004228992\n",
      "key  9  value[6]  0.39107838594488675\n",
      "key  10  value[6]  0.5474158342212556\n",
      "key  11  value[6]  1.0\n",
      "key  1 value[2]  0.04028342609023948\n",
      "key  2 value[2]  0.0769507041032482\n",
      "key  3 value[2]  0.11732652156883022\n",
      "key  4 value[2]  0.1638006653208015\n",
      "key  5 value[2]  0.21542734863188748\n",
      "key  6 value[2]  0.2786729678652965\n",
      "key  7 value[2]  0.3521722991452645\n",
      "key  8 value[2]  0.44280195170686026\n",
      "key  9 value[2]  0.5552471780392491\n",
      "key  10 value[2]  0.7171003470835221\n",
      "key  11 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.06725762117047643\n",
      "Current Error err_H 0.053805017325911135\n",
      "myFeeder.t  11\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00137027 0.01527495 ... 0.01784112 0.         0.        ]\n",
      " [0.         0.00044683 0.01500339 ... 0.01799947 0.         0.        ]\n",
      " [0.         0.0049151  0.02179226 ... 0.01821061 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.02980312 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.02973523 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.02973523 ... 0.01900238 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.02077393 ... 0.0192663  0.         0.        ]\n",
      " [0.         0.0005064  0.02124915 ... 0.01884402 0.         0.        ]\n",
      " [0.         0.00053619 0.02192804 ... 0.01889681 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00047662 0.03312967 ... 0.02491423 0.         0.        ]\n",
      " [0.         0.00047662 0.03312967 ... 0.02491423 0.         0.        ]\n",
      " [0.         0.00047662 0.03319756 ... 0.02491423 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00056598 0.02084182 ... 0.01889681 0.         0.        ]\n",
      " [0.         0.00041704 0.02002716 ... 0.01921351 0.         0.        ]\n",
      " [0.         0.00044683 0.02050238 ... 0.01931908 0.         0.        ]\n",
      " ...\n",
      " [0.         0.0005064  0.0221317  ... 0.01900238 0.         0.        ]\n",
      " [0.         0.0005064  0.0221317  ... 0.01900238 0.         0.        ]\n",
      " [0.         0.0005064  0.0221317  ... 0.01900238 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.02525458 ... 0.01836896 0.         0.        ]\n",
      " [0.         0.00044683 0.02576375 ... 0.01852732 0.         0.        ]\n",
      " [0.         0.00357462 0.02739308 ... 0.01821061 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.02504364 ... 0.01868567 0.         0.        ]\n",
      " [0.         0.00044683 0.02560372 ... 0.01868567 0.         0.        ]\n",
      " [0.         0.00044683 0.02560372 ... 0.01868567 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00759607 0.02342159 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.02443992 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00044683 0.02443992 ... 0.01821061 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.02647658 ... 0.01979414 0.         0.        ]\n",
      " [0.         0.00044683 0.02647658 ... 0.01979414 0.         0.        ]\n",
      " [0.         0.00044683 0.02647658 ... 0.01979414 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00397676 0.02678208 ... 0.01884402 0.         0.01777188]\n",
      " [0.         0.00049151 0.02841141 ... 0.01836896 0.         0.        ]\n",
      " [0.         0.01112601 0.02718941 ... 0.01797308 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00049151 0.03543788 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00049151 0.03564155 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00049151 0.03543788 ... 0.01900238 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.01757522 0.03095723 ... 0.01799947 0.         0.        ]\n",
      " [0.         0.01611558 0.02837746 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.01974978 0.02817379 ... 0.01805226 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00047662 0.0269518  ... 0.01900238 0.         0.        ]\n",
      " [0.         0.0005064  0.02701969 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00047662 0.02674813 ... 0.01900238 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00062556 0.03462322 ... 0.01876485 0.         0.        ]\n",
      " [0.         0.00049151 0.03533605 ... 0.01876485 0.         0.        ]\n",
      " [0.         0.05254692 0.06201629 ... 0.01852732 0.         0.00530504]\n",
      " ...\n",
      " [0.         0.00044683 0.03462322 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.03543788 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00049151 0.03625255 ... 0.01868567 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.02345845 0.04338086 ... 0.01844814 0.         0.        ]\n",
      " [0.         0.00044683 0.02759674 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.01818588 0.03482688 ... 0.01836896 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00049151 0.02912424 ... 0.01884402 0.         0.        ]\n",
      " [0.         0.00049151 0.02851324 ... 0.01876485 0.         0.        ]\n",
      " [0.         0.0080429  0.03034623 ... 0.01868567 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00047662 0.02640869 ... 0.02338348 0.         0.        ]\n",
      " [0.         0.00047662 0.02613714 ... 0.02385854 0.         0.        ]\n",
      " [0.         0.00047662 0.02545825 ... 0.02359462 0.         0.        ]\n",
      " ...\n",
      " [0.         0.0005064  0.02776646 ... 0.02153603 0.         0.        ]\n",
      " [0.         0.0005064  0.02769857 ... 0.02174716 0.         0.        ]\n",
      " [0.         0.00044683 0.02735913 ... 0.02164159 0.         0.        ]]\n",
      "list_RMSE_SousModele  [0.06918806257577613, 0.07011125308313815, 0.06781956041430064, 0.10699156955841346, 0.11046792675622191, 0.08401027188558187, 0.058684412919711944, 0.05874302840618986, 0.051271255076961265, 0.04251757996812928] mean of list_RMSE_SousModele 0.07198049206444246\n",
      " RMSE resultat vote 0.04638520930886627\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  R_Forest\n",
      "key  1  value[6]  0.10497512198316751\n",
      "key  2  value[6]  0.11586412658816056\n",
      "key  4  value[6]  0.1444116730248319\n",
      "key  5  value[6]  0.16334850821192484\n",
      "key  6  value[6]  0.18670485439918758\n",
      "key  7  value[6]  0.21615527050978905\n",
      "key  8  value[6]  0.25465259711919624\n",
      "key  9  value[6]  0.3081780004228992\n",
      "key  10  value[6]  0.39107838594488675\n",
      "key  11  value[6]  0.5474158342212556\n",
      "key  12  value[6]  1.0\n",
      "key  1 value[2]  0.03960715677343947\n",
      "key  2 value[2]  0.0761665882652048\n",
      "key  4 value[2]  0.11647343481292254\n",
      "key  5 value[2]  0.16188611022007685\n",
      "key  6 value[2]  0.2163004917768835\n",
      "key  7 value[2]  0.2783769615365617\n",
      "key  8 value[2]  0.35224448685554866\n",
      "key  9 value[2]  0.439758246684408\n",
      "key  10 value[2]  0.5551576736118708\n",
      "key  11 value[2]  0.7180939476404032\n",
      "key  12 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.06551825351534225\n",
      "Current Error err_H 0.04638520930886627\n",
      "myFeeder.t  12\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.02980312 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00053619 0.0299389  ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.03007468 ... 0.01879124 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.01432451 ... 0.01778833 0.         0.        ]\n",
      " [0.         0.00044683 0.01432451 ... 0.01810504 0.         0.        ]\n",
      " [0.         0.00044683 0.01432451 ... 0.01810504 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.03211134 ... 0.02412246 0.         0.        ]\n",
      " [0.         0.00047662 0.03129667 ... 0.02343626 0.         0.        ]\n",
      " [0.         0.00044683 0.03177189 ... 0.02385854 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00047662 0.02545825 ... 0.01842175 0.         0.        ]\n",
      " [0.         0.00047662 0.02545825 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.00047662 0.02545825 ... 0.01821061 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.0005064  0.0221317  ... 0.01900238 0.         0.        ]\n",
      " [0.         0.0005064  0.02118126 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.0005064  0.0221317  ... 0.01900238 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.01534284 ... 0.01884402 0.         0.        ]\n",
      " [0.         0.00044683 0.01534284 ... 0.01863288 0.         0.        ]\n",
      " [0.         0.00044683 0.01534284 ... 0.01863288 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.02540006 ... 0.01868567 0.         0.        ]\n",
      " [0.         0.00044683 0.02545825 ... 0.01868567 0.         0.        ]\n",
      " [0.         0.00044683 0.02525458 ... 0.01868567 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00053619 0.02800407 ... 0.02256532 0.         0.        ]\n",
      " [0.         0.00049151 0.02841141 ... 0.02343626 0.         0.        ]\n",
      " [0.         0.00049151 0.02841141 ... 0.02343626 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00049151 0.03492872 ... 0.01908155 0.         0.        ]\n",
      " [0.         0.00049151 0.03197556 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.0308554  ... 0.01900238 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00531725 0.02566191 ... 0.01805226 0.         0.03580902]\n",
      " [0.         0.00370867 0.02657841 ... 0.01955661 0.         0.02387268]\n",
      " [0.         0.00527256 0.02606925 ... 0.01987332 0.         0.03580902]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.02647658 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00047662 0.02593347 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.02579769 ... 0.01900238 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.02681602 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.0005064  0.02715547 ... 0.01821061 0.         0.        ]\n",
      " [0.         0.0005064  0.02715547 ... 0.01821061 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.03615071 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00044683 0.03431772 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00049151 0.03105906 ... 0.01900238 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00067024 0.03574338 ... 0.01900238 0.         0.        ]\n",
      " [0.         0.00062556 0.03431772 ... 0.0202692  0.         0.        ]\n",
      " [0.         0.00062556 0.03492872 ... 0.0202692  0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00049151 0.03014257 ... 0.01852732 0.         0.        ]\n",
      " [0.         0.00044683 0.03065173 ... 0.01836896 0.         0.        ]\n",
      " [0.         0.00049151 0.03044807 ... 0.01836896 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.0308554  ... 0.01995249 0.         0.01193634]\n",
      " [0.         0.00049151 0.02892057 ... 0.01916073 0.         0.01193634]\n",
      " [0.         0.00058088 0.02861507 ... 0.0189232  0.         0.01193634]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00047662 0.02776646 ... 0.02132489 0.         0.        ]\n",
      " [0.         0.00047662 0.02858113 ... 0.02069148 0.         0.        ]\n",
      " [0.         0.00053619 0.02946368 ... 0.01995249 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.03944331 ... 0.01947743 0.         0.        ]\n",
      " [0.         0.00044683 0.03781399 ... 0.02042755 0.         0.        ]\n",
      " [0.         0.00044683 0.03781399 ... 0.02042755 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "Output of each sub-model [[0.         0.00044683 0.03238289 ... 0.01828979 0.         0.        ]\n",
      " [0.         0.00049151 0.03329939 ... 0.01828979 0.         0.        ]\n",
      " [0.         0.00044683 0.03329939 ... 0.01821061 0.         0.        ]\n",
      " ...\n",
      " [0.         0.00044683 0.03360489 ... 0.02137767 0.         0.        ]\n",
      " [0.         0.00044683 0.03360489 ... 0.02019002 0.         0.        ]\n",
      " [0.         0.00044683 0.03268839 ... 0.02019002 0.         0.        ]]\n",
      "list_RMSE_SousModele  [0.07238253823210726, 0.07184187320530165, 0.07439543273245103, 0.11571158238596993, 0.08368822728863846, 0.059771472274923014, 0.06112952428365346, 0.06107215098440347, 0.04709025476679467, 0.05537089724733366] mean of list_RMSE_SousModele 0.07024539534015765\n",
      " RMSE resultat vote 0.04614801312730648\n",
      "vote is over\n",
      "Instance weights, recording current group performance, over\n",
      "Start adding new sub-models\n",
      "Randomly selected indique_sousModle  R_Forest\n",
      "key  1  value[6]  0.0957523625178593\n",
      "key  2  value[6]  0.10497512198316751\n",
      "key  4  value[6]  0.1288294285628787\n",
      "key  5  value[6]  0.1444116730248319\n",
      "key  7  value[6]  0.18670485439918758\n",
      "key  8  value[6]  0.21615527050978905\n",
      "key  9  value[6]  0.25465259711919624\n",
      "key  10  value[6]  0.3081780004228992\n",
      "key  11  value[6]  0.39107838594488675\n",
      "key  12  value[6]  0.5474158342212556\n",
      "key  13  value[6]  1.0\n",
      "key  1 value[2]  0.03960234397110376\n",
      "key  2 value[2]  0.07618534551733605\n",
      "key  4 value[2]  0.11652638637707119\n",
      "key  5 value[2]  0.16211316979843374\n",
      "key  7 value[2]  0.21667707201679928\n",
      "key  8 value[2]  0.27839245049056255\n",
      "key  9 value[2]  0.34924481390998496\n",
      "key  10 value[2]  0.437563089806583\n",
      "key  11 value[2]  0.5521290572558938\n",
      "key  12 value[2]  0.7112495630589233\n",
      "key  13 value[2]  1.0\n",
      "Average errors so far np.mean(errList) 0.06402823502395488\n",
      "Current Error err_H 0.04614801312730648\n",
      "myFeeder.t  13\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m8/612kxvld5rs5n06jrhs6dkt00000gn/T/ipykernel_25114/4197329009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Calculer la performance de Ht-1 à t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptionVote\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0myhat_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvote_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic_expert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactul_Batch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactul_Batch_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mafficher_detail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moptionVote\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0myhat_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvote_OnlyMaxWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic_expert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactul_Batch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactul_Batch_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/m8/612kxvld5rs5n06jrhs6dkt00000gn/T/ipykernel_25114/3314915975.py\u001b[0m in \u001b[0;36mvote_mean\u001b[0;34m(dic_expert, actul_Batch_X, actul_Batch_Y, afficher_detail)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic_expert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0myhat_sousM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakePredictionModele\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactul_Batch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat_sousM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/m8/612kxvld5rs5n06jrhs6dkt00000gn/T/ipykernel_25114/3314915975.py\u001b[0m in \u001b[0;36mmakePredictionModele\u001b[0;34m(modele, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m                           type(DecisionTreeRegressor())] :\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m  \u001b[0mmodele\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error reported, not in the list'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                 \u001b[0mparallel_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"prefer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"threads\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             chunked_results = Parallel(n_jobs, **parallel_kwargs)(\n\u001b[0m\u001b[1;32m    774\u001b[0m                 delayed(_tree_query_parallel_helper)(\n\u001b[1;32m    775\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \"\"\"\n\u001b[0;32m--> 597\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path_X_Y_data = 'simulationDonnes/'\n",
    "Y = np.load(path_X_Y_data + 'Y_CU_BEMS_19_normale_nettoy.npy' ,allow_pickle=True)\n",
    "X = np.load(path_X_Y_data + 'X_CU_BEMS_19_normale_nettoybackTimePoint3PCA10.npy' ,allow_pickle=True)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    dic_expert = {} # Maintain a dictionary of submodels\n",
    "    timeList, errList, innErrList, testErrNextBatchList,nFlodErr= [],[],[],[],[] #Time list, accuracy list etc.\n",
    "    Resulta_list, Ture_list = [],[] # Recorded information: predicted results and true values\n",
    "    ini_pourCentage = 0.01 # What percentage of data is used to initialize \n",
    "    testStar,testEnd = 0.2,0.99\n",
    "    HowManyDaysForBatch =14\n",
    "    batch_size = 1400*HowManyDaysForBatch# Block size\n",
    "    a,b = 0.35,1\n",
    "    time_Ini = 0 # The time required for initialization is recorded here\n",
    "    varepsilon_extreme_bord = 1.2 # Coefficient to check if the sub-model is working correctly \n",
    "    maxNumSousModle = 10 # Maximum number of sub-models\n",
    "    testBatchNum = 100 # Control the amount of batchs during the experiment\n",
    "    # optionPCA, PCA_size = True, 25\n",
    "    optionPCA, PCA_size = False, 25 # if the test dataset has been processed by PCA\n",
    "    # optitionInnErrOrCroissErr = 'InnErr'\n",
    "    optitionInnErrOrCroissErr = 'CroissErr'\n",
    "    optitionAddSousModele = True\n",
    "    optionVote ='Mean'\n",
    "    # optionVote ='OnlyMaxERRWeight'\n",
    "    # optionVote = 'vote_OnlyMaxESpWeight'\n",
    "    indicateur_sousModel = 'Random_LI_R_T_KNN' #['Random','LSTM','Lasso','KNN','R_Forest'] \n",
    "    cStepAugment = 1.4\n",
    "    updateOrNon = False\n",
    "\n",
    "\n",
    "    if optionPCA == True:\n",
    "        pca = PCA(n_components=PCA_size)\n",
    "        principalComponents = pca.fit_transform(X)\n",
    "        pca.explained_variance_ratio_\n",
    "        importance = pca.explained_variance_ratio_\n",
    "        plt.scatter(range(1,PCA_size+1),importance)\n",
    "        plt.plot(range(1,PCA_size+1),importance)\n",
    "        plt.title('Scree Plot')\n",
    "        plt.xlabel('Factors')\n",
    "        plt.ylabel('Eigenvalue')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        X = pca.fit_transform(X)\n",
    "    \n",
    "    myFeeder = feeder_Ini_Train_Batch(X,Y,testStar,testEnd,batch_size) # X,Y beginCentage,endCentage,batch_size \n",
    "    X_train,Y_train = myFeeder.getIni_X_Y(ini_pourCentage) \n",
    "    X_test,Y_test = myFeeder.getTrain_X_Y()\n",
    "\n",
    "    iniFlage = True\n",
    "\n",
    "    while ((testBatchNum > myFeeder.t)  and myFeeder.hasThisBatch()):\n",
    "\n",
    "        # Create an initialized sub-model, index 0\n",
    "        start_Ini = time.process_time()# Recording start time\n",
    "        if iniFlage == True:\n",
    "            Delta = [1/ myFeeder.batch_size]* myFeeder.batch_size \n",
    "            dic_expert[0], err_numFlod= RandonSelectionModle(0,X_train, Y_train,optitionInnErrOrCroissErr, indique_sousModle = indicateur_sousModel)\n",
    "            iniFlage = False\n",
    "        time_Ini = round(time.process_time()-start_Ini,5) # The time required for initialization is recorded here\n",
    "        start = time.process_time()# Recording start time \n",
    "        \n",
    "        #----------------VOTE------------------------------------------------------\n",
    "        actul_Batch_X, actul_Batch_Y  =  myFeeder.getThisBatch()\n",
    "        # Calculer la performance de Ht-1 à t \n",
    "        if optionVote == 'Mean':\n",
    "            yhat_H = vote_mean(dic_expert,actul_Batch_X, actul_Batch_Y,afficher_detail=True)\n",
    "        elif optionVote == 'Max':\n",
    "            yhat_H = vote_OnlyMaxWeight(dic_expert,actul_Batch_X, actul_Batch_Y)\n",
    "\n",
    "        print('vote is over')\n",
    "        #----------------------------------------------------------------------\n",
    "\n",
    "        #----------------Confirm instance weights and record current cluster performance------------------------------------------------------\n",
    "        ERR_absolu_H = np.abs(actul_Batch_Y - yhat_H) #ERR_absolu (martix)\n",
    "        Resulta_list.append(yhat_H)\n",
    "        Ture_list.append(actul_Batch_Y)\n",
    "        err_H = aRMSE(actul_Batch_Y,yhat_H)# err as RMSE \n",
    "        meanERR_absolu_H = np.mean(ERR_absolu_H, axis=1)\n",
    "\n",
    "        varepsilon_H = np.average(meanERR_absolu_H)\n",
    "        errList.append(err_H) \n",
    "        print('Instance weights, recording current group performance, over')\n",
    "        #----------------Confirm instance weights and record current cluster performance------------------------------------------------------\n",
    "\n",
    "        #----------------Alarm in case of abnormality------------------------------------------------------\n",
    "        if err_H >10:\n",
    "            print('time: ',myFeeder.t,'Une erreur majeure s est produite：',err_H) \n",
    "        #----------------Alarm in case of abnormality------------------------------------------------------\n",
    "\n",
    "\n",
    "        #------------------Add a new sub-model and confirm its weights (from cross-validation)-----------------------------\n",
    "        bord = 1 \n",
    "        while(optitionAddSousModele):\n",
    "            print('Start adding new sub-models')\n",
    "            dic_expert[myFeeder.t], yhat_new_numFlod = RandonSelectionModle(myFeeder.t, actul_Batch_X, actul_Batch_Y, optitionInnErrOrCroissErr,indique_sousModle = indicateur_sousModel)\n",
    "\n",
    "        \n",
    "            if optitionInnErrOrCroissErr == 'CroissErr':\n",
    "                ERR_absolu_new_numFlod = np.abs(actul_Batch_Y - yhat_new_numFlod) \n",
    "                meanERR_absolu_new_numFlod = np.mean(ERR_absolu_new_numFlod, axis=1)\n",
    "                err_new_numFlod = aRMSE(actul_Batch_Y,yhat_new_numFlod) \n",
    "                varepsilon_new = np.average(meanERR_absolu_new_numFlod,weights=Delta)\n",
    "                if varepsilon_new < varepsilon_H*bord:\n",
    "                    nFlodErr.append(err_new_numFlod)\n",
    "                    break\n",
    "                else:\n",
    "                    bord = bord*cStepAugment\n",
    "                \n",
    "            elif optitionInnErrOrCroissErr == 'InnErr':\n",
    "\n",
    "                yhat_new_inner = makePredictionModele(dic_expert[myFeeder.t][0], actul_Batch_X)\n",
    "                ERR_absolu_new_inner = np.abs(actul_Batch_Y - yhat_new_inner) \n",
    "                meanERR_absolu_new_inner = np.mean(ERR_absolu_new_inner, axis=1)\n",
    "                err_new_inner = aRMSE(actul_Batch_Y,yhat_new_inner) \n",
    "                varepsilon_new = np.average(meanERR_absolu_new_inner,weights=Delta)\n",
    "                break\n",
    "        #------------------Add a new sub-model and confirm its weights (from cross-validation)-----------------------------\n",
    "        \n",
    "        if optitionAddSousModele:\n",
    "            #------------------Recording training errors for new sub-models-----------------------------\n",
    "            yhat_new_inner = makePredictionModele(dic_expert[myFeeder.t][0], actul_Batch_X)\n",
    "            err_new_inner = aRMSE(actul_Batch_Y,yhat_new_inner)         \n",
    "            innErrList.append(err_new_inner)\n",
    "            #------------------Recording training errors for new sub-models-----------------------------\n",
    "\n",
    "            #------------------Test error of the model generated by the previous block in the next block-----------------------------\n",
    "            if myFeeder.hasThisBatch_and_nextBath():\n",
    "                next_batch_test_X,  next_batch_test_Y =  myFeeder.getNextBatch_getThisBatch()\n",
    "                yhat_next_batch_test = makePredictionModele(dic_expert[myFeeder.t][0], next_batch_test_X)\n",
    "                err_test_NextBatch = aRMSE(next_batch_test_Y, yhat_next_batch_test)         \n",
    "                testErrNextBatchList.append(err_test_NextBatch)\n",
    "            #------------------Test error of the model generated by the previous block in the next block-----------------------------\n",
    "\n",
    "\n",
    "        #------------------Calculate the performance of the old sub-model based on the weighted strengths in the current block-----------\n",
    "        Varepsilon_list = [] #Collection of the list of separate weighings of Varepsilon to facilitate the search for max-min values.\n",
    "        for key,value in dic_expert.items():\n",
    "            yhat_oldModel = makePredictionModele(value[0], actul_Batch_X)\n",
    "            ERR_absolu_oldModel = np.abs(actul_Batch_Y - yhat_oldModel)\n",
    "            mean_ERR_absolu_oldModel = np.mean(ERR_absolu_oldModel, axis=1)\n",
    "            err_oldModel = aRMSE(actul_Batch_Y,yhat_oldModel) # RMSE\n",
    "            varepsilon_oldModel = np.average(mean_ERR_absolu_oldModel,weights=Delta)\n",
    "    #         if varepsilon_oldModel > varepsilon_H*varepsilon_extreme_bord: \n",
    "    #             value[5] = varepsilon_H*varepsilon_extreme_bord\n",
    "    #         else:\n",
    "    #             value[5] = varepsilon_oldModel\n",
    "            value[5] = varepsilon_oldModel\n",
    "            Varepsilon_list.append(value[5])\n",
    "            value[7] = err_oldModel # enregrister RMSE\n",
    "    #         for key,value in dic_expert.items():   #normalisation \n",
    "    #             value[5] = (value[5] - min(Varepsilon_list))/(max(Varepsilon_list) - min(Varepsilon_list))\n",
    "    #     for key,value in dic_expert.items(): \n",
    "    #         print('key ', key, ' value[5] ', value[5] )\n",
    "        #------------------ calculates the performance of the old sub-model based on the weighted strengths in the current block (common error #7) and updates the weights (#5 based on weighting errors) -----------\n",
    "\n",
    "\n",
    "        #------------------Calculating time weights ----------\n",
    "        for key,value in dic_expert.items(): \n",
    "            numerator = beta_fonction(value[1],myFeeder.t,a,b)\n",
    "            denominator = 0\n",
    "            for j in range(0, myFeeder.t - value[1] +1): # \n",
    "                denominator +=  beta_fonction(myFeeder.t - j,myFeeder.t,a,b)\n",
    "#             print('denominator  ' , denominator)\n",
    "#             if  denominator == 0:\n",
    "#                 print(' myFeeder.t  ', myFeeder.t,' value[1]', value[1] )\n",
    "#                 for j in range(0, myFeeder.t - value[1] +1): # \n",
    "#                     print('j :', j , ' beta_fonction(myFeeder.t - j,myFeeder.t,a,b)', beta_fonction(myFeeder.t - j,myFeeder.t,a,b))\n",
    "            value[6] =  numerator/denominator\n",
    "        for key,value in dic_expert.items(): \n",
    "            print('key ', key, ' value[6] ', value[6] )\n",
    "        #------------------Calculating time weights ----------\n",
    "\n",
    "\n",
    "        #------------------Calculating sub-model weights-----------\n",
    "        # Calculer les poids des sous-modèles\n",
    "        weight_list = []\n",
    "        for key,value in dic_expert.items(): \n",
    "            denominator = 0 \n",
    "            for j in range(0, myFeeder.t - value[1] +1): #  from 0 to  t-k\n",
    "                if ((myFeeder.t-j) in dic_expert.keys()):\n",
    "                    denominator += dic_expert[myFeeder.t-j][6]*dic_expert[myFeeder.t-j][5]+0.1  # Omega weight * Error of current block being weighted    \n",
    "            value[2] = math.log(1/denominator)  \n",
    "            weight_list.append(math.log(1/denominator)) \n",
    "        for key,value in dic_expert.items(): \n",
    "            value[2] = (value[2] - min(weight_list)+0.1)/(max(weight_list) - min(weight_list)+0.1)\n",
    "        for key,value in dic_expert.items(): \n",
    "            print('key ', key, 'value[2] ',value[2] )\n",
    "        #------------------Calculating sub-model weights-----------\n",
    "\n",
    "\n",
    "        #------------------Removing the worst model -----------\n",
    "        if len(dic_expert) > maxNumSousModle:\n",
    "            maxErr = 0\n",
    "            del_key = 0\n",
    "            for key,value in dic_expert.items(): \n",
    "                if dic_expert[key][7] > maxErr:\n",
    "                    maxErr = dic_expert[key][7]\n",
    "                    del_key = key\n",
    "            dic_expert.pop(del_key)\n",
    "        #------------------Removing the worst model -----------\n",
    "        \n",
    "        \n",
    "        #------------------Whether the sub-model LSTM is updated----------- # 《This feature was deprecated》\n",
    "        if updateOrNon:\n",
    "            updatingALLSousModele(dic_expert,actul_Batch_X,actul_Batch_Y) \n",
    "        #------------------Whether the sub-model LSTM is updated-----------\n",
    "\n",
    "\n",
    "        # Recording time\n",
    "        timeList.append(round(time.process_time()-start,3))\n",
    "\n",
    "        print('Average errors so far np.mean(errList)', np.mean(errList))    #Show average of err\n",
    "        print('Current Error err_H', err_H) #Show err in Current\n",
    "\n",
    "        #Go to the next batch\n",
    "        print('myFeeder.t ', myFeeder.t)\n",
    "        myFeeder.goNext()\n",
    "\n",
    "        # print(errList)\n",
    "\n",
    "    #------------Store partial results-----------------\n",
    "    patch = \"resulta/\"\n",
    "    nameFileSave = \"CUBEM_resulta\"\n",
    "    # nameFileSave = \"UKDALE_resulta\"\n",
    "    res_oneTour = {}\n",
    "    res_oneTour['Resulta_list'] =  Resulta_list\n",
    "    res_oneTour['Ture_list'] =  Ture_list\n",
    "    np.save(patch + nameFileSave + '.npy', res_oneTour , allow_pickle=True, fix_imports=True)\n",
    "\n",
    "    break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "662px",
    "left": "601px",
    "right": "20px",
    "top": "121px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
